{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "     ---------------------------------------- 8.2/8.2 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.11.1-py3-none-any.whl (412 kB)\n",
      "     -------------------------------------- 412.8/412.8 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "     -------------------------------------- 330.3/330.3 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\navin.v.i.assyst-coc\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.0-cp311-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp311-none-win_amd64.whl (277 kB)\n",
      "     -------------------------------------- 277.5/277.5 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Collecting elastic-transport<9,>=8\n",
      "  Downloading elastic_transport-8.11.0-py3-none-any.whl (59 kB)\n",
      "     ---------------------------------------- 59.8/59.8 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.5.7)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "     -------------------------------------- 169.0/169.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navin.v.i.assyst-coc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: safetensors, fsspec, filelock, elastic-transport, huggingface-hub, elasticsearch, tokenizers, transformers\n",
      "Successfully installed elastic-transport-8.11.0 elasticsearch-8.11.1 filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.20.2 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: pytorch is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for pytorch did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\navin.v.i.ASSYST-COC\\AppData\\Local\\Temp\\pip-install-zwqod3k0\\pytorch_25bcfd20170d4868b95dff11e6d03ff7\\setup.py\", line 11, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> pytorch\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: pytorch\n",
      "  Running setup.py install for pytorch: started\n",
      "  Running setup.py install for pytorch: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\personal\\dev\\elastic-vector\\knn-search.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/personal/dev/elastic-vector/knn-search.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39melasticsearch\u001b[39;00m \u001b[39mimport\u001b[39;00m Elasticsearch\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/personal/dev/elastic-vector/knn-search.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/personal/dev/elastic-vector/knn-search.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m  \u001b[39mpytorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from elasticsearch import Elasticsearch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Elasticsearch connection with credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the mapping for the dense vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'properties': {\n",
    "'embedding': {\n",
    "'type': 'dense_vector',\n",
    "'dims': 768 # the number of dimensions of the dense vector\n",
    "}\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an index with the defined mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navin.v.i.ASSYST-COC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:397: SecurityWarning: Connecting to 'https://rag-search-using-elastic.es.us-central1.gcp.cloud.es.io:443' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "es = Elasticsearch(\n",
    "    ['https://rag-search-using-elastic.es.us-central1.gcp.cloud.es.io'],\n",
    "    basic_auth=('elastic', 'y0Wjxx5nEPyPyt8l07pDaTns'),\n",
    "    verify_certs=False\n",
    "    #ca_certs=\"A2525B64D8BFD084D946539261844AC9A3F7DBDC.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.create(index='chapter-2', body={'mappings': mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navin.v.i.ASSYST-COC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "model.safetensors: 100%|██████████| 440M/440M [03:05<00:00, 2.37MB/s] \n",
      "c:\\Users\\navin.v.i.ASSYST-COC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\navin.v.i.ASSYST-COC\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from elasticsearch import Elasticsearch\n",
    "import torch\n",
    "\n",
    "# Define a set of documents\n",
    "docs = [\n",
    "{\n",
    "'title': 'Document 1',\n",
    "'text': 'This is the first document.'\n",
    "},\n",
    "{\n",
    "'title': 'Document 2',\n",
    "'text': 'This is the second document.'\n",
    "},\n",
    "{\n",
    "'title': 'Document 3',\n",
    "'text': 'This is the third document.'\n",
    "}\n",
    "]\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the documents using BERT\n",
    "for doc in docs:\n",
    "    text = doc['text']\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs).last_hidden_state.mean(dim=1).squeeze(0).numpy()\n",
    "        doc['embedding'] = output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the documents in Elasticsearch\n",
    "for doc in docs:  es.index(index='chapter-2', body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'jokes-index'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index the verctors so that kNN search is properly done\n",
    "# first create the mapping\n",
    "mapping = {\n",
    "'properties': {\n",
    "'embedding': {\n",
    "'type': 'dense_vector',\n",
    "'dims': 768,\n",
    "'index': 'true',\n",
    "\"similarity\": \"cosine\"\n",
    "}\n",
    "}\n",
    "}\n",
    "es.indices.create(index='jokes-index', body={'mappings': mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke: What do you call a fake noodle? An impasta!\n",
      "Joke: What do you call a fake noodle? An impasta!\n",
      "Joke: What did the cat say when he lost all his money? I am paw.\n"
     ]
    }
   ],
   "source": [
    "jokes = [ \n",
    "    { \n",
    "        'text': 'Why do cats make terrible storytellers? Because they only have one tail.', \n",
    "        'category': 'cat' \n",
    "    }, \n",
    "    { \n",
    "        'text': 'What did the cat say when he lost all his money? I am paw.', \n",
    "        'category': 'cat' \n",
    "    }, \n",
    "    { \n",
    "        'text': 'Why don\\'t cats play poker in the jungle? Too many cheetahs.', \n",
    "        'category': 'cat' \n",
    "    },\n",
    "    { \n",
    "        'text': 'Why did the tomato turn red? Because it saw the salad dressing!', \n",
    "        'category': 'vegetable' \n",
    "    },\n",
    "    { \n",
    "        'text': 'Why did the scarecrow win an award? Because he was outstanding in his field.', \n",
    "        'category': 'farm' \n",
    "    },\n",
    "    { \n",
    "        'text': 'Why did the hipster burn his tongue? Because he drank his coffee before it was cool.', \n",
    "        'category': 'hipster' \n",
    "    },    \n",
    "    {\n",
    "        'text': 'Why did the tomato turn red? Because it saw the salad dressing!', \n",
    "        'category': 'food' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the scarecrow win an award? Because he was out-standing in his field!', \n",
    "        'category': 'puns' \n",
    "    },\n",
    "    {\n",
    "        'text': 'What do you call a fake noodle? An impasta!', \n",
    "        'category': 'food' \n",
    "    },\n",
    "    {\n",
    "        'text': 'What do you call a belt made out of watches? A waist of time!', \n",
    "        'category': 'puns' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the math book look sad? Because it had too many problems!', \n",
    "        'category': 'math' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the gym close down? It just didn\\'t work out!', \n",
    "        'category': 'exercise' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why don\\'t scientists trust atoms? Because they make up everything!', \n",
    "        'category': 'science' \n",
    "    },\n",
    "    {\n",
    "        'text': 'What do you call a fake noodle? An impasta!', \n",
    "        'category': 'food' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the chicken cross the playground? To get to the other slide!', \n",
    "        'category': 'kids' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the frog call his insurance company? He had a jump in his car!', \n",
    "        'category': 'puns' \n",
    "    }\n",
    "\n",
    "] \n",
    "# Load the BERT tokenizer and model \n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') \n",
    "model = AutoModel.from_pretrained('bert-base-uncased') \n",
    "\n",
    "# Generate embeddings for the jokes using BERT \n",
    "for joke in jokes: \n",
    "    text = joke['text'] \n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True) \n",
    "    with torch.no_grad(): \n",
    "        output = model(**inputs).last_hidden_state.mean(dim=1).squeeze(0).numpy() \n",
    "        joke['embedding'] = output.tolist() \n",
    "\n",
    "# Index the jokes in Elasticsearch \n",
    "for joke in jokes: \n",
    "    es.index(index='jokes-index', body=joke) \n",
    "\n",
    "# Define the query vector \n",
    "# Define a query text and convert it to a dense vector using BERT\n",
    "query = \"What do you get when you cross a snowman and a shark?\"\n",
    "inputs = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs).last_hidden_state.mean(dim=1).squeeze(0).numpy()\n",
    "query_vector = output\n",
    "\n",
    "# Define the Elasticsearch KNN search \n",
    "search = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"embedding\",\n",
    "        \"query_vector\": query_vector.tolist(),\n",
    "        \"k\": 3,\n",
    "        \"num_candidates\": 100\n",
    "    },\n",
    "    \"fields\": [ \"text\" ]\n",
    "}\n",
    "\n",
    "# Perform the KNN search and print the results \n",
    "response = es.search(index='jokes-index', body=search)\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Joke: {hit['_source']['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
